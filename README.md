# BOT-vCSGO-Beta v2.0

Sistema unificado de scrapers para arbitraje de items de CS:GO

## ğŸš€ InstalaciÃ³n RÃ¡pida

### 1. Clonar/Copiar el proyecto
```bash
# Si tienes git
git clone <tu-repositorio>
cd BOT-vCSGO-Beta

# O simplemente copia los archivos a una carpeta
```

### 2. Crear entorno virtual (recomendado)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar proxies (opcional)
Crea un archivo `proxy.txt` en la raÃ­z del proyecto con un proxy por lÃ­nea:
```
http://usuario:password@ip:puerto
http://ip:puerto
socks5://ip:puerto
```

## ğŸ¯ Uso BÃ¡sico

### Ver estado del sistema
```bash
python run_scrapers.py status
```

### Ejecutar un scraper
```bash
# Usar configuraciÃ³n global (proxy on/off segÃºn config)
python run_scrapers.py waxpeer

# Forzar uso de proxy
python run_scrapers.py waxpeer --proxy

# Forzar NO usar proxy
python run_scrapers.py waxpeer --no-proxy

# Ejecutar solo una vez (para pruebas)
python run_scrapers.py waxpeer --once
```

### Activar/Desactivar proxies globalmente
```bash
python run_scrapers.py toggle-proxy
```

## ğŸ”„ MigraciÃ³n desde la VersiÃ³n Antigua

### Paso 1: Migrar tus scrapers

Para cada par de archivos `Platform_noproxy.py` y `Platform_vproxy.py`, crea un Ãºnico archivo en `backend/scrapers/platform_scraper.py`:

```python
# backend/scrapers/csdeals_scraper.py
from backend.core.base_scraper import BaseScraper

class CSDealsScraper(BaseScraper):
    def __init__(self, use_proxy=None):
        super().__init__('CSDeals', use_proxy)
        self.api_url = "https://cs.deals/API/IPricing/GetLowestPrices/v1?appid=730"
    
    def fetch_data(self):
        response = self.make_request(self.api_url)
        if response:
            return self.parse_response(response)
        return []
    
    def parse_response(self, response):
        # Tu lÃ³gica de parsing aquÃ­
        data = response.json()
        items = []
        # ... procesar datos ...
        return items
```

### Paso 2: Copiar tus archivos de configuraciÃ³n

```bash
# Copiar configuraciones existentes
cp Configs/Language.json config/
cp Configs/Notifications.json config/notifications/thresholds.json
cp Configs/Api.json config/api_keys.json  # âš ï¸ No subir a git!
```

### Paso 3: Actualizar el diccionario de scrapers

En `run_scrapers.py`, agregar tus scrapers migrados:

```python
from backend.scrapers.csdeals_scraper import CSDealsScraper
from backend.scrapers.empire_scraper import EmpireScraper

SCRAPERS = {
    'waxpeer': WaxpeerScraper,
    'csdeals': CSDealsScraper,    # Agregar
    'empire': EmpireScraper,       # Agregar
    # ... mÃ¡s scrapers
}
```

## ğŸ“ Estructura del Proyecto

```
BOT-vCSGO-Beta/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ core/               # Sistema base
â”‚   â”‚   â”œâ”€â”€ base_scraper.py    # Clase base (elimina duplicaciÃ³n)
â”‚   â”‚   â”œâ”€â”€ config_manager.py  # GestiÃ³n de configuraciÃ³n
â”‚   â”‚   â””â”€â”€ proxy_manager.py   # GestiÃ³n de proxies
â”‚   â”‚
â”‚   â””â”€â”€ scrapers/           # Tus scrapers
â”‚       â”œâ”€â”€ waxpeer_scraper.py
â”‚       â”œâ”€â”€ csdeals_scraper.py
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ config/                 # Configuraciones
â”‚   â”œâ”€â”€ settings.json          # Config principal
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â””â”€â”€ platforms.json     # Config por plataforma
â”‚   â””â”€â”€ notifications/
â”‚       â””â”€â”€ thresholds.json    # Umbrales de notificaciÃ³n
â”‚
â”œâ”€â”€ JSON/                   # Salida de datos (generado)
â”œâ”€â”€ logs/                   # Archivos de log (generado)
â”‚
â”œâ”€â”€ run_scrapers.py         # Script principal
â”œâ”€â”€ requirements.txt        # Dependencias
â”œâ”€â”€ proxy.txt              # Lista de proxies (crear)
â””â”€â”€ README.md              # Este archivo
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar intervalos de actualizaciÃ³n

Editar `config/scrapers/platforms.json`:

```json
{
    "waxpeer": {
        "update_interval": 60,  // segundos
        "api_url": "https://..."
    }
}
```

### Cambiar umbrales de rentabilidad

Editar `config/notifications/thresholds.json`:

```json
{
    "profitability_waxpeer": 0.5,
    "profitability_empire": 1.2
}
```

### Variables de entorno (recomendado para API keys)

Crear archivo `.env`:
```
WAXPEER_API_KEY=tu-api-key
EMPIRE_API_KEY=tu-api-key
```

## ğŸ› SoluciÃ³n de Problemas

### "No module named 'backend'"
```bash
# AsegÃºrate de ejecutar desde la raÃ­z del proyecto
cd BOT-vCSGO-Beta
python run_scrapers.py status
```

### "No se encontrÃ³ proxy.txt"
- El archivo proxy.txt es opcional
- Si quieres usar proxies, crÃ©alo en la raÃ­z del proyecto
- Un proxy por lÃ­nea

### "Error al conectar"
- Verifica tu conexiÃ³n a internet
- Si usas proxy, verifica que funcionen
- Algunos sitios pueden bloquear requests frecuentes

## ğŸš¦ PrÃ³ximos Pasos

1. **Migrar todos tus scrapers** al nuevo formato
2. **Configurar la base de datos** (prÃ³ximamente)
3. **Agregar interfaz web** (prÃ³ximamente)
4. **Sistema de notificaciones** (prÃ³ximamente)

## ğŸ“ Notas de la MigraciÃ³n

### Ventajas del nuevo sistema:
- âœ… Un solo archivo por plataforma (no mÃ¡s _proxy y _noproxy)
- âœ… ConfiguraciÃ³n centralizada
- âœ… GestiÃ³n inteligente de proxies
- âœ… Mejor manejo de errores
- âœ… Logs estructurados
- âœ… FÃ¡cil de mantener y extender

### Lo que se mantiene igual:
- ğŸ“ Los archivos JSON de salida tienen el mismo formato
- ğŸ”„ La lÃ³gica de negocio es la misma
- ğŸ“Š Los cÃ¡lculos de rentabilidad no cambian

## ğŸ¤ Contribuir

1. Migra un scraper
2. Prueba que funcione
3. Documenta cualquier problema
4. Comparte mejoras

---

**VersiÃ³n**: 2.0.0  
**Autor**: ZoluGames  
**Licencia**: MIT